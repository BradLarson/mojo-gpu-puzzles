<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mojo GPU Puzzles</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/css/custom.css">
        <link rel="stylesheet" href="theme/css/highlight.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <!-- Modular-style custom header -->
                <div class="modular-header">
                    <div class="modular-logo-container">
                        <a href="index.html" class="modular-logo">
                            <img src="brandmark-light.svg" alt="Mojo Logo" class="light-logo" />
                            <img src="brandmark-dark.svg" alt="Mojo Logo" class="dark-logo" />
                            <span class="modular-title">Mojo<span style="color: #ff5e00;">🔥</span> GPU Puzzles</span>
                        </a>
                    </div>
                    <div class="modular-nav">
                        <a href="https://docs.modular.com/mojo" class="nav-link" target="_blank">Mojo Docs</a>
                        <a href="https://github.com/modularml/mojo-gpu-puzzles" class="nav-link" target="_blank">GitHub</a>
                    </div>
                </div>
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Mojo GPU Puzzles</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/modularml/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mojo-gpu-puzzles"><a class="header" href="#mojo-gpu-puzzles">Mojo GPU Puzzles</a></h1>
<p>A collection of interactive puzzles to learn GPU programming in Mojo.</p>
<h2 id="accompanying-materials"><a class="header" href="#accompanying-materials">Accompanying Materials</a></h2>
<ul>
<li><a href="https://docs.modular.com/mojo/manual/gpu/basics">GPU basics</a></li>
<li><a href="https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0128119861">Programming Massively Parallel Processors: A Hands-on Approach</a></li>
</ul>
<h2 id="about-this-book"><a class="header" href="#about-this-book">About This Book</a></h2>
<p>This book contains a series of puzzles designed to teach GPU programming concepts using Mojo.
Each puzzle focuses on a specific concept and provides a hands-on opportunity to implement
GPU kernels.</p>
<p>The puzzles progress from basic concepts to more advanced topics:</p>
<ol>
<li>Simple mapping operations</li>
<li>Multi-dimensional data handling</li>
<li>Shared memory usage</li>
<li>Advanced algorithms like convolution and prefix sums</li>
<li>Matrix operations</li>
</ol>
<h2 id="how-to-use-this-book"><a class="header" href="#how-to-use-this-book">How to Use This Book</a></h2>
<p>For each puzzle:</p>
<ol>
<li>Read the problem description and understand the task</li>
<li>Implement the missing code in the corresponding file in the <code>problems/</code> directory</li>
<li>Run the code using <code>magic run &lt;problem_file&gt;</code></li>
<li>Check your output against the expected output</li>
</ol>
<p>Let’s get started with the first puzzle!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-1-map"><a class="header" href="#puzzle-1-map">Puzzle 1: Map</a></h1>
<p>Implement a “kernel” (GPU function) that adds 10 to each position of vector <code>a</code>
and stores it in vector <code>out</code>. You have 1 thread per position.</p>
<h2 id="problem"><a class="header" href="#problem">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p01.mojo">problems/p01.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 4
alias BLOCKS_PER_GRID = 1
alias THREADS_PER_BLOCK = SIZE
alias dtype = DType.float32

fn add_10(out: UnsafePointer[Scalar[dtype]], a: UnsafePointer[Scalar[dtype]]):
    local_i = thread_idx.x
    # FILL ME IN (roughly 1 line)
</code></pre>
<h2 id="visual-representation"><a class="header" href="#visual-representation">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_14_1.svg" alt="Map operation visualization" /></p>
<h2 id="running-the-code"><a class="header" href="#running-the-code">Running the Code</a></h2>
<pre><code class="language-bash">magic run p01
</code></pre>
<h2 id="expected-output"><a class="header" href="#expected-output">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
</code></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Basic GPU kernel structure</li>
<li>Mapping thread indices to data indices</li>
<li>Parallel execution of independent operations</li>
</ul>
<p>The key insight is that each thread (identified by <code>thread_idx.x</code>) should process one element of the input array.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-2-zip"><a class="header" href="#puzzle-2-zip">Puzzle 2: Zip</a></h1>
<p>Implement a kernel that adds together each position of <code>a</code> and <code>b</code> and stores it in <code>out</code>.
You have 1 thread per position.</p>
<h2 id="problem-1"><a class="header" href="#problem-1">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p02.mojo">problems/p02.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 4
alias BLOCKS_PER_GRID = 1
alias THREADS_PER_BLOCK = SIZE
alias dtype = DType.float32


fn add(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
):
    local_i = thread_idx.x
    # FILL ME IN (roughly 1 line)
</code></pre>
<h2 id="visual-representation-1"><a class="header" href="#visual-representation-1">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_17_1.svg" alt="Zip operation visualization" /></p>
<h2 id="running-the-code-1"><a class="header" href="#running-the-code-1">Running the Code</a></h2>
<pre><code class="language-bash">magic run p02
</code></pre>
<h2 id="expected-output-1"><a class="header" href="#expected-output-1">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([0.0, 2.0, 4.0, 6.0])
</code></pre>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Processing multiple input arrays in parallel</li>
<li>Element-wise operations with multiple inputs</li>
<li>Maintaining thread-to-data mapping across arrays</li>
</ul>
<p>Each thread should read one element from each input array, add them together, and write the result to the output array.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-3-guards"><a class="header" href="#puzzle-3-guards">Puzzle 3: Guards</a></h1>
<p>Implement a kernel that adds 10 to each position of <code>a</code> and stores it in <code>out</code>.
You have more threads than positions.</p>
<h2 id="problem-2"><a class="header" href="#problem-2">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p03.mojo">problems/p03.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 4
alias BLOCKS_PER_GRID = 1
alias THREADS_PER_BLOCK = (8, 1)
alias dtype = DType.float32


fn add_10_guard(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    local_i = thread_idx.x
    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-2"><a class="header" href="#visual-representation-2">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_21_1.svg" alt="Guards visualization" /></p>
<h2 id="running-the-code-2"><a class="header" href="#running-the-code-2">Running the Code</a></h2>
<pre><code class="language-bash">magic run p03
</code></pre>
<h2 id="expected-output-2"><a class="header" href="#expected-output-2">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
</code></pre>
<h2 id="key-concepts-2"><a class="header" href="#key-concepts-2">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Using guards to handle thread/data size mismatches</li>
<li>Preventing out-of-bounds memory access</li>
<li>Conditional execution in GPU kernels</li>
</ul>
<p>The key insight is that you need to check if a thread’s index is within the valid range of the data array before performing any operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-4-map-2d"><a class="header" href="#puzzle-4-map-2d">Puzzle 4: Map 2D</a></h1>
<p>Implement a kernel that adds 10 to each position of <code>a</code> and stores it in <code>out</code>.
Input <code>a</code> is 2D and square. You have more threads than positions.</p>
<h2 id="problem-3"><a class="header" href="#problem-3">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p04.mojo">problems/p04.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 2
alias BLOCKS_PER_GRID = 1
alias THREADS_PER_BLOCK = (3, 3)
alias dtype = DType.float32


fn add_10_2d(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    local_i = thread_idx.x
    local_j = thread_idx.y
    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-3"><a class="header" href="#visual-representation-3">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_24_1.svg" alt="Map 2D visualization" /></p>
<h2 id="running-the-code-3"><a class="header" href="#running-the-code-3">Running the Code</a></h2>
<pre><code class="language-bash">magic run p04
</code></pre>
<h2 id="expected-output-3"><a class="header" href="#expected-output-3">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
</code></pre>
<h2 id="key-concepts-3"><a class="header" href="#key-concepts-3">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Working with 2D thread configurations</li>
<li>Mapping 2D thread indices to 1D memory</li>
<li>Implementing boundary checks in multiple dimensions</li>
</ul>
<p>The key insight is understanding how to convert 2D coordinates to a 1D memory index using row-major ordering, and ensuring that your thread indices are within the bounds of the 2D data.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-5-broadcast"><a class="header" href="#puzzle-5-broadcast">Puzzle 5: Broadcast</a></h1>
<p>Implement a kernel that adds <code>a</code> and <code>b</code> and stores it in <code>out</code>.
Inputs <code>a</code> and <code>b</code> are vectors. You have more threads than positions.</p>
<h2 id="problem-4"><a class="header" href="#problem-4">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p05.mojo">problems/p05.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 2
alias BLOCKS_PER_GRID = 1
alias THREADS_PER_BLOCK = (3, 3)
alias dtype = DType.float32


fn broadcast_add(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    local_i = thread_idx.x
    local_j = thread_idx.y
    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-4"><a class="header" href="#visual-representation-4">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_27_1.svg" alt="Broadcast visualization" /></p>
<h2 id="running-the-code-4"><a class="header" href="#running-the-code-4">Running the Code</a></h2>
<pre><code class="language-bash">magic run p05
</code></pre>
<h2 id="expected-output-4"><a class="header" href="#expected-output-4">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([0.0, 1.0, 1.0, 2.0])
</code></pre>
<h2 id="key-concepts-4"><a class="header" href="#key-concepts-4">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Broadcasting operations across dimensions</li>
<li>Processing 1D data with 2D thread configurations</li>
<li>Coordinate conversion between thread and data indices</li>
</ul>
<p>The key insight is understanding how to map 2D thread coordinates to 1D memory indices for the operation, while also ensuring proper boundary checking.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-6-blocks"><a class="header" href="#puzzle-6-blocks">Puzzle 6: Blocks</a></h1>
<p>Implement a kernel that adds 10 to each position of <code>a</code> and stores it in <code>out</code>.
You have fewer threads per block than the size of <code>a</code>.</p>
<h2 id="problem-5"><a class="header" href="#problem-5">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p06.mojo">problems/p06.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 9
alias BLOCKS_PER_GRID = (3, 1)
alias THREADS_PER_BLOCK = (4, 1)
alias dtype = DType.float32


fn add_10_blocks(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-5"><a class="header" href="#visual-representation-5">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_31_1.svg" alt="Blocks visualization" /></p>
<h2 id="running-the-code-5"><a class="header" href="#running-the-code-5">Running the Code</a></h2>
<pre><code class="language-bash">magic run p06
</code></pre>
<h2 id="expected-output-5"><a class="header" href="#expected-output-5">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0])
</code></pre>
<h2 id="key-concepts-5"><a class="header" href="#key-concepts-5">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Working with multiple blocks of threads</li>
<li>Computing global thread indices</li>
<li>Understanding the block/thread hierarchy in GPU programming</li>
</ul>
<p>A block is a group of threads. The number of threads per block is limited, but we can have many different blocks. The variable <a href="https://docs.modular.com/mojo/stdlib/gpu/id#aliases">block_idx</a> tells us what block we are in.</p>
<p>The key insight is understanding how to compute the global thread index using the block index, and ensuring that this index doesn’t exceed the data size.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-7-blocks-2d"><a class="header" href="#puzzle-7-blocks-2d">Puzzle 7: Blocks 2D</a></h1>
<p>Implement the same kernel in 2D. You have fewer threads per block
than the size of <code>a</code> in both directions.</p>
<h2 id="problem-6"><a class="header" href="#problem-6">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p07.mojo">problems/p07.mojo</a>.</p>
<pre><code class="language-mojo">alias SIZE = 5
alias BLOCKS_PER_GRID = (2, 2)
alias THREADS_PER_BLOCK = (3, 3)
alias dtype = DType.float32


fn add_10_blocks_2d(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    global_j = block_dim.y * block_idx.y + thread_idx.y
    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-6"><a class="header" href="#visual-representation-6">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_34_1.svg" alt="Blocks 2D visualization" /></p>
<h2 id="running-the-code-6"><a class="header" href="#running-the-code-6">Running the Code</a></h2>
<pre><code class="language-bash">magic run p07
</code></pre>
<h2 id="expected-output-6"><a class="header" href="#expected-output-6">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
</code></pre>
<h2 id="key-concepts-6"><a class="header" href="#key-concepts-6">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Working with 2D block configurations</li>
<li>Computing global thread indices in multiple dimensions</li>
<li>Mapping 2D thread/block indices to memory locations</li>
</ul>
<p>The key insight is understanding how to compute global thread indices in a 2D grid, convert them to a linear memory index, and ensure that these indices don’t exceed the data size in either dimension.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-8-shared"><a class="header" href="#puzzle-8-shared">Puzzle 8: Shared</a></h1>
<p>Implement a kernel that adds 10 to each position of <code>a</code> and stores it in <code>out</code>.
You have fewer threads per block than the size of <code>a</code>.</p>
<h2 id="problem-7"><a class="header" href="#problem-7">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p08.mojo">problems/p08.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 4
alias SIZE = 8
alias BLOCKS_PER_GRID = (2, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32


fn add_10_shared(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # local data into shared memory
    if global_i &lt; size:
        shared[local_i] = a[global_i]

    # wait for all threads to complete
    # works within a thread block
    barrier()

    # FILL ME IN (roughly 2 lines)
</code></pre>
<h2 id="visual-representation-7"><a class="header" href="#visual-representation-7">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_39_1.svg" alt="Shared memory visualization" /></p>
<h2 id="running-the-code-7"><a class="header" href="#running-the-code-7">Running the Code</a></h2>
<pre><code class="language-bash">magic run p08
</code></pre>
<h2 id="expected-output-7"><a class="header" href="#expected-output-7">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
</code></pre>
<h2 id="key-concepts-7"><a class="header" href="#key-concepts-7">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Using shared memory within a thread block</li>
<li>Synchronizing threads with barriers</li>
<li>The importance of thread synchronization in shared memory operations</li>
</ul>
<p><strong>Warning</strong>: Each block can only have a <em>constant</em> amount of shared memory that threads in that block can read and write to. This needs to be a literal python constant, not a variable. After writing to shared memory you need to call <a href="https://docs.modular.com/mojo/stdlib/gpu/sync/barrier/">barrier</a> to ensure that threads do not cross.</p>
<p>Even though this example doesn’t strictly require shared memory or barriers, it introduces these concepts for more complex operations in future puzzles.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-9-pooling"><a class="header" href="#puzzle-9-pooling">Puzzle 9: Pooling</a></h1>
<p>Implement a kernel that sums together the last 3 position of <code>a</code> and stores it in <code>out</code>.
You have 1 thread per position. You only need 1 global read and 1 global write per thread.</p>
<h2 id="problem-8"><a class="header" href="#problem-8">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p09.mojo">problems/p09.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 8
alias SIZE = 8
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32


fn pooling(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # FILL ME IN (roughly 8 lines)
</code></pre>
<h2 id="visual-representation-8"><a class="header" href="#visual-representation-8">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_43_1.svg" alt="Pooling visualization" /></p>
<h2 id="running-the-code-8"><a class="header" href="#running-the-code-8">Running the Code</a></h2>
<pre><code class="language-bash">magic run p09
</code></pre>
<h2 id="expected-output-8"><a class="header" href="#expected-output-8">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([0.0, 1.0, 3.0, 6.0, 9.0, 12.0, 15.0, 18.0])
</code></pre>
<h2 id="key-concepts-8"><a class="header" href="#key-concepts-8">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Implementing pooling operations using shared memory</li>
<li>Accessing adjacent elements in shared memory</li>
<li>Managing thread synchronization for dependent operations</li>
</ul>
<p><em>Tip: Remember to be careful about syncing when accessing shared memory.
Each thread needs to load its data and wait for others before performing the pooling operation.</em></p>
<p>The key insight is understanding how to efficiently implement a sliding window operation using shared memory, where each thread’s output depends on multiple input values.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-10-dot-product"><a class="header" href="#puzzle-10-dot-product">Puzzle 10: Dot Product</a></h1>
<p>Implement a kernel that computes the dot-product of <code>a</code> and <code>b</code> and stores it in <code>out</code>.
You have 1 thread per position. You only need 2 global reads and 1 global write per thread.</p>
<h2 id="problem-9"><a class="header" href="#problem-9">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p10.mojo">problems/p10.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 8
alias SIZE = 8
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (SIZE, 1)
alias dtype = DType.float32


fn dot_product(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # FILL ME IN (roughly 11 lines)
</code></pre>
<h2 id="visual-representation-9"><a class="header" href="#visual-representation-9">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_47_1.svg" alt="Dot product visualization" /></p>
<h2 id="running-the-code-9"><a class="header" href="#running-the-code-9">Running the Code</a></h2>
<pre><code class="language-bash">magic run p10
</code></pre>
<h2 id="expected-output-9"><a class="header" href="#expected-output-9">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0])
expected: HostBuffer([140.0])
</code></pre>
<h2 id="key-concepts-9"><a class="header" href="#key-concepts-9">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Implementing reduction operations (like dot product)</li>
<li>Using shared memory for thread collaboration</li>
<li>Understanding parallel reduction patterns</li>
</ul>
<p><em>Note: For this problem, you don’t need to worry about number of shared reads. We will
handle that challenge later.</em></p>
<p>The key insight is understanding how to compute partial results in parallel, then combine them efficiently using shared memory and synchronization to produce a final result.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-11-1d-convolution"><a class="header" href="#puzzle-11-1d-convolution">Puzzle 11: 1D Convolution</a></h1>
<p>Implement a kernel that computes a 1D convolution between <code>a</code> and <code>b</code> and stores it in <code>out</code>.
You need to handle the general case. You only need 2 global reads and 1 global write per thread.</p>
<h2 id="problem-10"><a class="header" href="#problem-10">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p11.mojo">problems/p11.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 8
alias SIZE = 6
alias CONV = 3
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32

fn conv_1d_simple(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    a_size: Int,
    b_size: Int,
):
    shared_a = stack_allocation[
        SIZE * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    shared_b = stack_allocation[
        CONV * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # FILL ME IN (roughly 11 lines)
</code></pre>
<h2 id="visual-representation-10"><a class="header" href="#visual-representation-10">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_50_1.svg" alt="1D Convolution visualization" /></p>
<h2 id="running-the-code-10"><a class="header" href="#running-the-code-10">Running the Code</a></h2>
<pre><code class="language-bash">magic run p11
</code></pre>
<h2 id="expected-output-10"><a class="header" href="#expected-output-10">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([5.0, 8.0, 11.0, 14.0, 5.0, 0.0])
</code></pre>
<h2 id="key-concepts-10"><a class="header" href="#key-concepts-10">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Implementing convolution operations on GPUs</li>
<li>Managing boundary conditions in convolution</li>
<li>Efficient shared memory usage for sliding window operations</li>
</ul>
<p>The key insight is understanding how to load both the input array and the convolution kernel into shared memory, then compute the convolution result for each position while handling boundary conditions correctly.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-12-prefix-sum"><a class="header" href="#puzzle-12-prefix-sum">Puzzle 12: Prefix Sum</a></h1>
<p>Implement a kernel that computes a running sum / prefix-sum over <code>a</code> and stores it in <code>out</code>.
If the size of <code>a</code> is greater than the block size, only store the sum of
each block.</p>
<h2 id="problem-11"><a class="header" href="#problem-11">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p12.mojo">problems/p12.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 8
alias SIZE = 8
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32

# this only works when there's a single block
fn prefix_sum_simple(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # FILL ME IN (roughly 11 lines)
</code></pre>
<h2 id="algorithm-explanation"><a class="header" href="#algorithm-explanation">Algorithm Explanation</a></h2>
<p>We will use the <a href="https://en.wikipedia.org/wiki/Prefix_sum">parallel prefix sum</a> algorithm in shared memory.
That is, each step of the algorithm should sum together half the remaining numbers.
Follow this diagram:</p>
<p><img src="https://user-images.githubusercontent.com/35882/178757889-1c269623-93af-4a2e-a7e9-22cd55a42e38.png" alt="Prefix Sum Algorithm" /></p>
<h2 id="visual-representation-11"><a class="header" href="#visual-representation-11">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_58_1.svg" alt="Prefix Sum visualization" /></p>
<h2 id="running-the-code-11"><a class="header" href="#running-the-code-11">Running the Code</a></h2>
<pre><code class="language-bash">magic run p12
</code></pre>
<h2 id="expected-output-11"><a class="header" href="#expected-output-11">Expected Output</a></h2>
<pre><code class="language-txt">out: DeviceBuffer([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0])
</code></pre>
<h2 id="key-concepts-11"><a class="header" href="#key-concepts-11">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Implementing parallel prefix sum (scan) operations</li>
<li>Using shared memory for efficient parallel computation</li>
<li>Understanding parallel algorithms with logarithmic complexity</li>
</ul>
<p>The key insight is implementing the parallel prefix sum algorithm, which consists of two phases: an up-sweep phase that builds a sum tree, and a down-sweep phase that builds the final prefix sum.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-13-axis-sum"><a class="header" href="#puzzle-13-axis-sum">Puzzle 13: Axis Sum</a></h1>
<p>Implement a kernel that computes a sum over each column of <code>a</code> and stores it in <code>out</code>.</p>
<h2 id="problem-12"><a class="header" href="#problem-12">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p13.mojo">problems/p13.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 8
alias BATCH = 4
alias SIZE = 6
alias BLOCKS_PER_GRID = (1, BATCH)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32

fn axis_sum(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    cache = stack_allocation[
        TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    batch = block_idx.y
    # FILL ME IN (roughly 12 lines)
</code></pre>
<h2 id="visual-representation-12"><a class="header" href="#visual-representation-12">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_64_1.svg" alt="Axis Sum visualization" /></p>
<h2 id="running-the-code-12"><a class="header" href="#running-the-code-12">Running the Code</a></h2>
<pre><code class="language-bash">magic run p13
</code></pre>
<h2 id="expected-output-12"><a class="header" href="#expected-output-12">Expected Output</a></h2>
<pre><code class="language-txt">out: DeviceBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([15.0, 51.0, 87.0, 123.0])
</code></pre>
<h2 id="key-concepts-12"><a class="header" href="#key-concepts-12">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Computing reductions along specific dimensions (axes)</li>
<li>Using multiple thread blocks to process different parts of data</li>
<li>Mapping thread blocks to specific data columns/regions</li>
</ul>
<p>The key insight is organizing your computation to have separate thread blocks handle different columns of the input array, then using shared memory within each block to compute the sum efficiently.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puzzle-14-matrix-multiply"><a class="header" href="#puzzle-14-matrix-multiply">Puzzle 14: Matrix Multiply</a></h1>
<p>Implement a kernel that multiplies square matrices <code>a</code> and <code>b</code> and
stores the result in <code>out</code>.</p>
<h2 id="problem-13"><a class="header" href="#problem-13">Problem</a></h2>
<p>The file for this puzzle is <a href="../problems/p14.mojo">problems/p14.mojo</a>.</p>
<pre><code class="language-mojo">alias TPB = 3
alias SIZE = 2
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, TPB)

fn single_block_matmul(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    a_shared = stack_allocation[
        TPB * TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    b_shared = stack_allocation[
        TPB * TPB * sizeof[dtype](),
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    global_j = block_dim.y * block_idx.y + thread_idx.y
    local_i = thread_idx.x
    local_j = thread_idx.y
    # FILL ME IN (roughly 6 lines)
</code></pre>
<h2 id="visual-representation-13"><a class="header" href="#visual-representation-13">Visual Representation</a></h2>
<p><img src="https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_67_1.svg" alt="Matrix Multiply visualization" /></p>
<h2 id="running-the-code-13"><a class="header" href="#running-the-code-13">Running the Code</a></h2>
<pre><code class="language-bash">magic run p14
</code></pre>
<h2 id="expected-output-13"><a class="header" href="#expected-output-13">Expected Output</a></h2>
<pre><code class="language-txt">out: HostBuffer([0.0, 0.0, 0.0, 0.0])
expected: HostBuffer([1.0, 3.0, 3.0, 13.0])
</code></pre>
<h2 id="key-concepts-13"><a class="header" href="#key-concepts-13">Key Concepts</a></h2>
<p>In this puzzle, you’ll learn about:</p>
<ul>
<li>Implementing matrix multiplication on GPU</li>
<li>Using shared memory to optimize memory access patterns</li>
<li>Organizing thread blocks for matrix operations</li>
</ul>
<p>The key insight is loading blocks of both matrices into shared memory and computing partial products efficiently. This is a fundamental operation in many GPU applications, particularly in machine learning and scientific computing.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="theme/highlight.js"></script>
        <script src="theme/init.js"></script>

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
